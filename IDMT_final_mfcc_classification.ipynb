{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXpZ2HsmAPJu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhkdtKaOBW9o"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Data/IDMT_full_mfcc_final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8Y69pftBXBn"
      },
      "outputs": [],
      "source": [
        "arr=np.load(\"/content/drive/MyDrive/Data/features_full_mfcc_final.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['vehicle'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW8DeSY4zgdG",
        "outputId": "dd8396be-a627-4b79-c925-fb001332abf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "None    4071\n",
              "C       3902\n",
              "T        268\n",
              "M        246\n",
              "Name: vehicle, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJvY9a40BXQI"
      },
      "outputs": [],
      "source": [
        "X=arr\n",
        "y=np.array(df['vehicle'].tolist())\n",
        "### Label Encoding -> Label Encoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))\n",
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(X_train))\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(y_train))\n",
        "print(np.shape(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIUYEHYxjCqM",
        "outputId": "dc347eac-49a3-4fa0-aa29-724f56308384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5940, 128, 87)\n",
            "(2547, 128, 87)\n",
            "(5940, 4)\n",
            "(2547, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7hc5yfBBl-D"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets, layers, models,Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv3D,MaxPool1D,Conv2D,Conv1D,MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqzwx7NGBq_i"
      },
      "outputs": [],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMjmSBfRBrC7"
      },
      "outputs": [],
      "source": [
        "nn = models.Sequential([\n",
        "        layers.Conv1D(input_shape=(128,87),filters=64,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=2),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv1D(filters=64,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=2),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv1D(filters=32,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=3),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv1D(filters=16,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(500, activation='relu'),\n",
        "        layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(4, activation='softmax')    \n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G-PzQ37BvTS",
        "outputId": "75b24ede-c274-46ce-810a-d8b50b3b038b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "186/186 [==============================] - 15s 11ms/step - loss: 0.6207 - accuracy: 0.8290 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2203 - accuracy: 0.9311 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.1857 - accuracy: 0.9431 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.1357 - accuracy: 0.9579 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9663 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9677 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0914 - accuracy: 0.9731 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9694 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9742 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9773 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9737 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "182/186 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9773\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0755 - accuracy: 0.9769 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0589 - accuracy: 0.9815 - lr: 5.0000e-04\n",
            "Epoch 14/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0495 - accuracy: 0.9847 - lr: 5.0000e-04\n",
            "Epoch 15/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0546 - accuracy: 0.9808 - lr: 5.0000e-04\n",
            "Epoch 16/30\n",
            "178/186 [===========================>..] - ETA: 0s - loss: 0.0558 - accuracy: 0.9833\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9835 - lr: 5.0000e-04\n",
            "Epoch 17/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0434 - accuracy: 0.9850 - lr: 2.5000e-04\n",
            "Epoch 18/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0418 - accuracy: 0.9855 - lr: 2.5000e-04\n",
            "Epoch 19/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0470 - accuracy: 0.9848 - lr: 2.5000e-04\n",
            "Epoch 20/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0414 - accuracy: 0.9859 - lr: 2.5000e-04\n",
            "Epoch 21/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0452 - accuracy: 0.9877 - lr: 2.5000e-04\n",
            "Epoch 22/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0414 - accuracy: 0.9859 - lr: 2.5000e-04\n",
            "Epoch 23/30\n",
            "182/186 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9863\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0389 - accuracy: 0.9864 - lr: 2.5000e-04\n",
            "Epoch 24/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0379 - accuracy: 0.9889 - lr: 1.2500e-04\n",
            "Epoch 25/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9887 - lr: 1.2500e-04\n",
            "Epoch 26/30\n",
            "186/186 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9880\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9880 - lr: 1.2500e-04\n",
            "Epoch 27/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9892 - lr: 6.2500e-05\n",
            "Epoch 28/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0334 - accuracy: 0.9887 - lr: 6.2500e-05\n",
            "Epoch 29/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0336 - accuracy: 0.9894 - lr: 6.2500e-05\n",
            "Epoch 30/30\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0315 - accuracy: 0.9889 - lr: 6.2500e-05\n"
          ]
        }
      ],
      "source": [
        "nn.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history=nn.fit(X_train, y_train, epochs=30,callbacks = [learning_rate_reduction])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9V0oxB0BvWR",
        "outputId": "0575ddaf-2d5a-4630-a426-a36ffab26fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9924\n",
            "Accuracy of the model on Training Data is -  99.24242496490479 %\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9894\n",
            "Accuracy of the model on Testing Data is -  98.93993139266968 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of the model on Training Data is - \" , nn.evaluate(X_train,y_train)[1]*100 , \"%\")\n",
        "print(\"Accuracy of the model on Testing Data is - \" , nn.evaluate(X_test,y_test)[1]*100 , \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IcU1RicBvZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f0ea8c-0dc5-4f2b-e37c-6146613a37ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0]\n",
            " [0 0 1 0]]\n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "[[[1368   14]\n",
            "  [  11 1154]]\n",
            "\n",
            " [[2475    0]\n",
            "  [   2   70]]\n",
            "\n",
            " [[1312    7]\n",
            "  [   5 1223]]\n",
            "\n",
            " [[2461    4]\n",
            "  [   9   73]]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1165\n",
            "           1       1.00      0.97      0.99        72\n",
            "           2       0.99      1.00      1.00      1228\n",
            "           3       0.95      0.89      0.92        82\n",
            "\n",
            "   micro avg       0.99      0.99      0.99      2547\n",
            "   macro avg       0.98      0.96      0.97      2547\n",
            "weighted avg       0.99      0.99      0.99      2547\n",
            " samples avg       0.99      0.99      0.99      2547\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import sklearn.metrics as skm\n",
        "\n",
        "# y_predict=nn.predict(X_test)\n",
        "y_predict=(nn.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(y_predict[0:2])\n",
        "y_true=y_test\n",
        "print(y_true)\n",
        "\n",
        "# res = tf.math.confusion_matrix(y_true,y_predict)\n",
        "cm = skm.multilabel_confusion_matrix(y_true, y_predict)\n",
        "print(cm)\n",
        "print( skm.classification_report(y_true,y_predict))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}