{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXpZ2HsmAPJu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhkdtKaOBW9o"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Data/IDMT_full_melspec_final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8Y69pftBXBn"
      },
      "outputs": [],
      "source": [
        "arr=np.load(\"/content/drive/MyDrive/Data/features_full_melspec_final.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['vehicle'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW8DeSY4zgdG",
        "outputId": "7cfd7380-4210-4f05-f102-b4cfc0ee1634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "None    4071\n",
              "C       3902\n",
              "T        268\n",
              "M        246\n",
              "Name: vehicle, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJvY9a40BXQI"
      },
      "outputs": [],
      "source": [
        "X=arr\n",
        "y=np.array(df['vehicle'].tolist())\n",
        "### Label Encoding -> Label Encoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))\n",
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(X_train))\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(y_train))\n",
        "print(np.shape(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIUYEHYxjCqM",
        "outputId": "92ce62e7-855a-4f54-c3c2-90335fc847bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5940, 128, 87)\n",
            "(2547, 128, 87)\n",
            "(5940, 4)\n",
            "(2547, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7hc5yfBBl-D"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets, layers, models,Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv3D,MaxPool1D,Conv2D,Conv1D,MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqzwx7NGBq_i"
      },
      "outputs": [],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMjmSBfRBrC7"
      },
      "outputs": [],
      "source": [
        "nn = models.Sequential([\n",
        "        layers.Conv1D(input_shape=(128,87),filters=64,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=2),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv1D(filters=64,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=2),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv1D(filters=32,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=3),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv1D(filters=16,kernel_size=3,padding='same', activation='relu'),\n",
        "        layers.MaxPool1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(500, activation='relu'),\n",
        "        layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(4, activation='softmax')    \n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G-PzQ37BvTS",
        "outputId": "9c904f91-7264-4e8b-aa00-8500046536a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "186/186 [==============================] - 16s 8ms/step - loss: 0.3840 - accuracy: 0.9098 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.1432 - accuracy: 0.9512 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.1350 - accuracy: 0.9567 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9613 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0935 - accuracy: 0.9685 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.1062 - accuracy: 0.9633 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0992 - accuracy: 0.9690 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9737 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0639 - accuracy: 0.9773 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0736 - accuracy: 0.9749 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "179/186 [===========================>..] - ETA: 0s - loss: 0.0644 - accuracy: 0.9764\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0631 - accuracy: 0.9768 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0524 - accuracy: 0.9833 - lr: 5.0000e-04\n",
            "Epoch 13/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0514 - accuracy: 0.9848 - lr: 5.0000e-04\n",
            "Epoch 14/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0442 - accuracy: 0.9842 - lr: 5.0000e-04\n",
            "Epoch 15/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0376 - accuracy: 0.9880 - lr: 5.0000e-04\n",
            "Epoch 16/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0403 - accuracy: 0.9877 - lr: 5.0000e-04\n",
            "Epoch 17/30\n",
            "184/186 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9871\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0355 - accuracy: 0.9872 - lr: 5.0000e-04\n",
            "Epoch 18/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.9896 - lr: 2.5000e-04\n",
            "Epoch 19/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0313 - accuracy: 0.9886 - lr: 2.5000e-04\n",
            "Epoch 20/30\n",
            "181/186 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9895\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9894 - lr: 2.5000e-04\n",
            "Epoch 21/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0283 - accuracy: 0.9899 - lr: 1.2500e-04\n",
            "Epoch 22/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0250 - accuracy: 0.9911 - lr: 1.2500e-04\n",
            "Epoch 23/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0255 - accuracy: 0.9907 - lr: 1.2500e-04\n",
            "Epoch 24/30\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9928 - lr: 1.2500e-04\n",
            "Epoch 25/30\n",
            "186/186 [==============================] - 2s 10ms/step - loss: 0.0229 - accuracy: 0.9906 - lr: 1.2500e-04\n",
            "Epoch 26/30\n",
            "183/186 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9916\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "186/186 [==============================] - 2s 10ms/step - loss: 0.0230 - accuracy: 0.9918 - lr: 1.2500e-04\n",
            "Epoch 27/30\n",
            "186/186 [==============================] - 2s 10ms/step - loss: 0.0257 - accuracy: 0.9904 - lr: 6.2500e-05\n",
            "Epoch 28/30\n",
            "186/186 [==============================] - 2s 10ms/step - loss: 0.0215 - accuracy: 0.9938 - lr: 6.2500e-05\n",
            "Epoch 29/30\n",
            "186/186 [==============================] - 1s 7ms/step - loss: 0.0205 - accuracy: 0.9926 - lr: 6.2500e-05\n",
            "Epoch 30/30\n",
            "184/186 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9927\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9926 - lr: 6.2500e-05\n"
          ]
        }
      ],
      "source": [
        "nn.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history=nn.fit(X_train, y_train, epochs=30,callbacks = [learning_rate_reduction])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9V0oxB0BvWR",
        "outputId": "d380479d-6ee1-4f3a-f92a-951c74f60035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9961\n",
            "Accuracy of the model on Training Data is -  99.61279630661011 %\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.1193 - accuracy: 0.9808\n",
            "Accuracy of the model on Testing Data is -  98.0761706829071 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of the model on Training Data is - \" , nn.evaluate(X_train,y_train)[1]*100 , \"%\")\n",
        "print(\"Accuracy of the model on Testing Data is - \" , nn.evaluate(X_test,y_test)[1]*100 , \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IcU1RicBvZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159a5314-1d3d-47d5-97a1-3bc7ec69b4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0]\n",
            " [0 0 1 0]]\n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]]\n",
            "[[[1356   24]\n",
            "  [  15 1152]]\n",
            "\n",
            " [[2468    8]\n",
            "  [   3   68]]\n",
            "\n",
            " [[1320    4]\n",
            "  [  16 1207]]\n",
            "\n",
            " [[2449   12]\n",
            "  [  15   71]]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      1167\n",
            "           1       0.89      0.96      0.93        71\n",
            "           2       1.00      0.99      0.99      1223\n",
            "           3       0.86      0.83      0.84        86\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      2547\n",
            "   macro avg       0.93      0.94      0.94      2547\n",
            "weighted avg       0.98      0.98      0.98      2547\n",
            " samples avg       0.98      0.98      0.98      2547\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import sklearn.metrics as skm\n",
        "\n",
        "# y_predict=nn.predict(X_test)\n",
        "y_predict=(nn.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(y_predict[0:2])\n",
        "y_true=y_test\n",
        "print(y_true)\n",
        "\n",
        "# res = tf.math.confusion_matrix(y_true,y_predict)\n",
        "cm = skm.multilabel_confusion_matrix(y_true, y_predict)\n",
        "print(cm)\n",
        "print( skm.classification_report(y_true,y_predict))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}